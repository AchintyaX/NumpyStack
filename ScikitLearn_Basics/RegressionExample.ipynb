{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are using regression here, Regression is different from classification\n",
    "# In classification we have to seperate the data into different categories \n",
    "# while in regression we have to use the input data to make prediction for future data\n",
    "# like predicting the price of stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us get the dataset \n",
    "\n",
    "# about the dataset:\n",
    "# NASA data set, obtained from a series of aerodynamic and acoustic tests of two and three-dimensional airfoil blade sections conducted in an anechoic wind tunnel.\n",
    "df = pd.read_csv('airfoil_self_noise.dat', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>126.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>125.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>71.3</td>\n",
       "      <td>0.002663</td>\n",
       "      <td>127.461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1       2     3         4        5\n",
       "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
       "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
       "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
       "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
       "4  2000  0.0  0.3048  71.3  0.002663  127.461"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503 entries, 0 to 1502\n",
      "Data columns (total 6 columns):\n",
      "0    1503 non-null int64\n",
      "1    1503 non-null float64\n",
      "2    1503 non-null float64\n",
      "3    1503 non-null float64\n",
      "4    1503 non-null float64\n",
      "5    1503 non-null float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 70.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our data ready\n",
    "data = df[[0,1,2,3,4,5]].values\n",
    "# we are using the values function whose job is the same as the as_matrix\n",
    "# the as_matrix() is going to be removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting our targets ready\n",
    "target = df[5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting our model\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training our data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here the score is not an accuracy but it is the mean relative mean square error\n",
    "model.score(X_train, y_train)\n",
    "# 1 is still good only, and close to one is appreciated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([113.004, 118.291, 127.556, 121.771, 133.211, 127.71 , 113.525,\n",
       "       121.313, 125.683, 135.329, 123.988, 130.541, 112.945, 118.343,\n",
       "       127.233, 129.119, 131.491, 130.156, 124.106, 134.928, 126.944,\n",
       "       120.963, 123.312, 110.905, 122.45 , 127.696, 120.015, 112.506,\n",
       "       132.395, 128.907, 127.315, 124.839, 134.976, 131.236, 124.692,\n",
       "       136.883, 126.457, 112.93 , 121.485, 127.076, 124.222, 134.568,\n",
       "       110.364, 118.618, 120.575, 113.796, 128.345, 132.252, 122.966,\n",
       "       125.094, 119.708, 130.893, 119.039, 130.567, 122.905, 122.088,\n",
       "       121.225, 130.307, 112.209, 122.175, 110.313, 119.91 , 118.619,\n",
       "       124.625, 119.854, 127.054, 129.367, 118.994, 132.54 , 134.111,\n",
       "       130.715, 138.274, 120.458, 133.611, 132.301, 119.146, 128.518,\n",
       "       113.775, 121.635, 114.569, 132.658, 122.411, 128.401, 135.674,\n",
       "       115.234, 123.917, 127.006, 125.586, 125.741, 123.303, 122.708,\n",
       "       117.151, 124.353, 135.328, 121.627, 122.845, 135.234, 129.491,\n",
       "       103.38 , 127.903, 124.318, 125.499, 133.956, 134.43 , 122.147,\n",
       "       131.642, 125.319, 114.477, 118.122, 126.406, 135.924, 133.097,\n",
       "       134.556, 136.886, 119.541, 118.024, 115.591, 127.548, 126.045,\n",
       "       123.126, 129.296, 133.174, 125.724, 115.372, 122.211, 132.595,\n",
       "       124.717, 133.846, 123.455, 123.236, 127.408, 128.677, 127.564,\n",
       "       110.264, 128.339, 130.46 , 115.608, 132.793, 114.927, 112.589,\n",
       "       124.493, 118.564, 131.43 , 125.647, 131.978, 128.763, 116.55 ,\n",
       "       127.299, 121.146, 116.241, 117.789, 124.838, 128.381, 129.285,\n",
       "       119.253, 125.194, 130.065, 126.514, 125.127, 129.377, 117.386,\n",
       "       126.736, 120.716, 119.07 , 136.826, 123.807, 124.852, 117.478,\n",
       "       116.92 , 121.889, 131.274, 131.518, 118.743, 135.54 , 117.396,\n",
       "       119.343, 107.405, 126.896, 129.004, 125.268, 130.829, 123.835,\n",
       "       124.355, 126.17 , 117.957, 109.951, 131.448, 114.779, 125.963,\n",
       "       123.865, 125.715, 126.677, 111.534, 123.207, 128.99 , 130.392,\n",
       "       130.961, 127.634, 112.768, 120.607, 130.688, 128.427, 135.191,\n",
       "       125.305, 129.633, 124.986, 122.149, 124.393, 114.634, 127.179,\n",
       "       124.121, 122.79 , 122.229, 124.156, 135.938, 115.812, 126.644,\n",
       "       128.809, 123.217, 126.826, 120.397, 121.664, 113.129, 122.606,\n",
       "       135.07 , 130.   , 130.34 , 132.513, 116.181, 130.206, 129.991,\n",
       "       117.785, 115.91 , 128.257, 114.418, 110.905, 111.818, 126.413,\n",
       "       118.712, 129.148, 133.04 , 131.807, 128.296, 127.91 , 130.183,\n",
       "       122.082, 128.633, 121.059, 129.953, 129.965, 127.864, 118.113,\n",
       "       123.839, 133.48 , 128.36 , 133.587, 109.885, 122.675, 112.251,\n",
       "       131.111, 126.049, 120.243, 117.967, 130.748, 117.309, 122.679,\n",
       "       125.527, 136.031, 117.093, 120.766, 116.56 , 132.897, 120.534,\n",
       "       131.955, 128.857, 114.258, 119.916, 120.264, 108.991, 127.054,\n",
       "       135.956, 113.958, 122.315, 114.453, 127.893, 127.206, 115.818,\n",
       "       114.309, 132.611, 122.101, 107.267, 116.677, 132.918, 122.919,\n",
       "       125.997, 131.656, 128.423, 129.645, 130.94 , 115.792, 113.034,\n",
       "       136.758, 123.177, 131.036, 122.428, 109.718, 130.348, 119.229,\n",
       "       125.484, 134.476, 133.376, 112.014, 122.754, 136.191, 120.229,\n",
       "       121.499, 104.204, 123.894, 126.886, 126.465, 135.38 , 129.937,\n",
       "       118.365, 126.514, 120.324, 127.314, 115.391, 129.33 , 132.039,\n",
       "       122.893, 115.413, 117.253, 123.705, 128.723, 130.089, 121.903,\n",
       "       117.911, 130.086, 129.673, 114.044, 114.404, 126.001, 124.439,\n",
       "       124.338, 131.458, 115.304, 128.956, 134.853, 123.565, 114.67 ,\n",
       "       125.586, 121.66 , 123.127, 131.582, 133.311, 133.79 , 129.579,\n",
       "       129.147, 131.434, 133.664, 123.054, 125.452, 128.435, 113.297,\n",
       "       131.725, 132.043, 124.809, 119.621, 127.246, 108.185, 122.435,\n",
       "       126.959, 131.605, 120.419, 127.591, 123.12 , 128.978, 123.775,\n",
       "       123.209, 129.744, 113.08 , 132.116, 114.249, 119.505, 121.528,\n",
       "       115.996, 126.537, 120.538, 134.319, 137.233, 125.809, 127.7  ,\n",
       "       133.649, 115.635, 124.426, 122.365, 132.118, 134.498, 116.417,\n",
       "       140.987, 109.949, 122.205, 123.595, 128.144, 129.053, 116.128,\n",
       "       109.663, 121.783, 128.401, 133.071, 130.987, 117.287, 131.864,\n",
       "       114.861, 135.459, 125.603, 128.536, 127.614, 117.137, 122.235,\n",
       "       126.752, 130.299, 110.447, 124.904, 110.689, 123.178, 120.569,\n",
       "       127.637, 122.044, 118.998, 119.159, 125.201, 139.918, 120.509,\n",
       "       127.623, 133.847, 129.468, 135.227, 126.986, 127.591, 125.401,\n",
       "       134.273, 129.556, 121.318, 129.267, 126.933, 124.525, 123.74 ,\n",
       "       132.184, 125.472, 124.024, 130.828, 133.04 , 123.862, 123.274,\n",
       "       125.802, 123.609, 139.808, 120.835, 128.867, 126.266, 118.05 ,\n",
       "       128.707, 120.527, 127.365, 130.725, 132.149, 129.099, 122.371,\n",
       "       113.334, 133.252, 129.949, 127.398, 129.653, 115.52 , 134.43 ,\n",
       "       122.17 , 125.524, 112.065, 136.837, 124.685, 133.012, 126.159,\n",
       "       138.423, 131.221, 126.534, 132.358, 130.777, 118.767, 119.649,\n",
       "       115.321, 123.543, 131.456, 116.229, 110.515, 130.05 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us use neural networks this time\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/achintya/.local/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99503811350084"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9954242046804798"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
